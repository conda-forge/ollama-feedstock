{% set name = "ollama" %}
{% set goname = "github.com/ollama/ollama" %}
{% set version = "0.5.12" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  - url: https://{{ goname }}/archive/v{{ version }}.tar.gz
    sha256: a38d5e3ce4ee13d237ef670231016d02ee81cb880f38d58795e989c73b5b7523
    folder: .

build:
  skip: true  # [win and cuda_compiler_version not in ("None", )]
  number: 0
  string: cuda{{ cuda_compiler_version | replace('.', '') }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
  string: cpu_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [(osx and x86_64) or cuda_compiler_version == "None"]
  string: mps_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [osx and arm64]
  script:
    - make
    - mv ./ollama $PREFIX/bin/ollama
    - go-licenses save --save_path licenses ./...

requirements:
  build:
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }}                    # [cuda_compiler_version not in (undefined, "None")]
    - {{ compiler('go') }}
    - {{ stdlib("c") }}
    - go-licenses

    - git
    - cmake
    - make

test:
  commands:
    - ollama --version
    - ollama --help

about:
  home: https://ollama.ai
  summary: Get up and running with Llama 2 and other large language models locally
  license: MIT
  license_family: MIT
  license_file:
    - LICENSE
    - licenses/
  dev_url: https://{{ goname }}

extra:
  recipe-maintainers:
    - sodre
    - benmoss
