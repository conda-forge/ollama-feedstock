{% set name = "ollama" %}
{% set goname = "github.com/jmorganca/ollama" %}
# DO NOT AUTO MERGE WITHOUT VERIFYING THE GIT_REVISIONS OF ggml AND gguf
{% set version = "0.1.14" %}
{% set ggml_version = "master-9e232f0" %}
{% set ggml_sha256 = "e93334c097c7b6ce17eed47d44934b9354ee29b5ab4f572999547c2d1a2d46ef" %}
{% set gguf_version = "b1412" %}
{% set gguf_sha256 = "9c127ec8a6c54e7c03e2a246a41382ce7df7c4e46543bc7fec685600d6e2e6d9" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  - url: https://{{ goname }}/archive/v{{ version }}.tar.gz
    sha256: 789a64e5f8da0cd71ff3ed339fe1b47727a44f6c009c0e3c4c094990b64cbd8b
    folder: .
    patches:
      # Use the same build options from llama.cpp-feedstock
      - 0001-darwin_amd64.patch
      - 0001-darwin_arm64.patch
      - 0001-remove-submodule.patch
      - 0001-linux_all-do-not-copy-cuda.patch
  - url: https://github.com/ggerganov/llama.cpp/archive/{{ ggml_version }}.tar.gz
    folder: llm/llama.cpp/ggml
    sha256: {{ ggml_sha256 }}
  - url: https://github.com/ggerganov/llama.cpp/archive/{{ gguf_version }}.tar.gz
    folder: llm/llama.cpp/gguf
    sha256: {{ gguf_sha256 }}

build:
  number: 0
  skip: true  # [win and cuda_compiler_version != "None"]
  string: cuda{{ cuda_compiler_version | replace('.', '') }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
  string: mps_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [osx and arm64]
  string: cpu_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [(osx and x86_64) or cuda_compiler_version == "None"]
  script:
    - git config --system user.email "conda-forge@numfocus.org"
    - git config --system user.name "Conda Forge"
    - git config --global init.defaultBranch main
    {% for framework in ["ggml", "gguf"] %}
    - |
      pushd llm/llama.cpp/{{ framework }}
      git init
      git add .
      git commit -m "conda-forge build"
      popd
    {% endfor %}
    - export GOFLAGS="'-ldflags=-X=github.com/jmorganca/ollama/version.Version={{ version }} -X=github.com/jmorganca/ollama/server.mode=release'"
    - go generate ./...
    - go install .                                                                                                            # [build_platform == target_platform]
    # TODO: This is due to a bug in our go-lang patch 
    #       Error message is go install can't write to GOBIN when cross compiling
    - unset CONDA_GO_COMPILER; GOPATH=$SRC_DIR/gopath go install .; mkdir -p $PREFIX/bin; cp gopath/bin/*/ollama $PREFIX/bin  # [build_platform != target_platform]
    - go-licenses save --save_path licenses ./...

  ignore_run_exports_from:
    # llama.cpp server is staticially linked on osx
    - {{ compiler('cxx') }}  # [osx]

requirements:
  build:
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }}                    # [cuda_compiler_version not in (undefined, "None")]
    - {{ compiler('go') }} 1.20
    - go-licenses

    - git
    - cmake
    - make                                      # [unix]

    # Tool can't find cudart/cublas in the host-environment
    - cuda-cudart-dev                           # [(cuda_compiler_version or "").startswith("12")]
    - libcublas-dev                             # [(cuda_compiler_version or "").startswith("12")]
  host:
    - cuda-cudart-dev                           # [(cuda_compiler_version or "").startswith("12")]
    - libcublas-dev                             # [(cuda_compiler_version or "").startswith("12")]
  run:
    - cuda-version {{ cuda_compiler_version }}  # [cuda_compiler_version not in (undefined, "None")]
    - cuda-cudart                               # [(cuda_compiler_version or "").startswith("12")]

test:
  commands:
    - ollama --version
    - ollama --help

about:
  home: https://ollama.ai
  summary: Get up and running with Llama 2 and other large language models locally
  license: MIT
  license_family: MIT
  license_file:
    - LICENSE
    - licenses/
  dev_url: https://{{ goname }}

extra:
  recipe-maintainers:
    - sodre
