context:
  version: "0.9.1-ci3"
  cuda: ${{ "true" if cuda_compiler_version != "None" else "" }}
  cuda_build_string: cuda_${{ cuda_compiler_version | version_to_buildstring }}
  string_prefix: ${{ cuda_build_string if cuda else "cpu_" }}

package:
  name: ollama
  version: ${{ version }}

source:
  url: https://github.com/ollama/ollama/archive/refs/tags/v${{ version }}.tar.gz
  sha256: fc060bf7ec4f22620f3561cd4775f48c21d0e776817f812ad3b1369f7787b0fe

build:
  number: 0
  string: ${{ string_prefix }}h${{ hash }}_${{ build_number }}
  variant:
    use_keys:
      # use cuda from the variant config, e.g. to build multiple CUDA variants
      - ${{ "cuda" if cuda }}
    # this will down-prioritize the cuda variant versus other variants of the package
    down_prioritize_variant: ${{ 1 if cuda == "true" else 0 }}
  script:
    - if: win
      then: [build.bat]
      else: [build.sh]
  skip:
    - cuda and match(cuda_compiler_version, "<12")

requirements:
  build:
    - ${{ compiler('go-cgo') }}
    - cmake
    - make
    - go-licenses
    - if: win
      then:
        - ${{ stdlib('m2w64_c') }}
        - ${{ compiler('m2w64_cxx') }}
      else:
        - ${{ stdlib('c') }}
        - ${{ compiler('cxx') }}
    - if: cuda
      then:
        - ${{ compiler('cuda') }}
        - cuda-version ==${{ cuda_compiler_version }}
  host:
    - if: cuda
      then:
        - cuda-version ==${{ cuda_compiler_version }}
        - libcublas-dev
  ignore_run_exports:
    from_package:
      - if: cuda
        then: libcublas-dev
tests:
  - script:
      - ollama --version

about:
  homepage: https://ollama.com/
  repository: https://github.com/ollama/ollama
  documentation: https://github.com/ollama/ollama
  summary: Ollama CLI
  description: |
    Ollama is an easy way to get local language models running on your computer through a command-line interface.
  license: MIT
  license_file:
    - LICENSE
    - license-files/

extra:
  recipe-maintainers:
    - sodre
    - benmoss
